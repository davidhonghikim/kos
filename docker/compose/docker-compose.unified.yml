name: ai-q

services:
  # Main AI-Q Application Container
  ai-q-app:
    build:
      context: ../..
      dockerfile: docker/dockerfiles/Dockerfile.unified
    container_name: ai-q-unified-app
    environment:
      # Application Settings
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - API_HOST=${API_HOST:-0.0.0.0}
      - API_PORT=${API_PORT:-8000}
      - WEB_PORT=${WEB_PORT:-3000}
      - JWT_SECRET=${JWT_SECRET:-}
      
      # Database Settings
      - POSTGRES_DB=${POSTGRES_DB:-aiq_knowledge}
      - POSTGRES_USER=${POSTGRES_USER:-aiq_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-aiq_password}
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=${POSTGRES_PORT:-5432}
      
      # Redis Settings
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      
      # Elasticsearch Settings
      - ELASTICSEARCH_HOST=${ELASTICSEARCH_HOST:-elasticsearch}
      - ELASTICSEARCH_PORT=${ELASTICSEARCH_PORT:-9200}
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-elastic}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-elastic}
      
      # Neo4j Settings
      - NEO4J_HOST=${NEO4J_HOST:-neo4j}
      - NEO4J_PORT=${NEO4J_PORT:-7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-password}
      
      # Weaviate Settings
      - WEAVIATE_HOST=${WEAVIATE_HOST:-weaviate}
      - WEAVIATE_PORT=${WEAVIATE_PORT:-8080}
      
      # MinIO Settings
      - MINIO_HOST=${MINIO_HOST:-minio}
      - MINIO_PORT=${MINIO_PORT:-9000}
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      
      # Monitoring Settings
      - PROMETHEUS_HOST=${PROMETHEUS_HOST:-prometheus}
      - PROMETHEUS_PORT=${PROMETHEUS_PORT:-9090}
      - GRAFANA_HOST=${GRAFANA_HOST:-grafana}
      - GRAFANA_PORT=${GRAFANA_PORT:-3000}
      - CADVISOR_HOST=${CADVISOR_HOST:-cadvisor}
      - CADVISOR_PORT=${CADVISOR_PORT:-8081}
      
      # AI/ML Services
      - HUGGINGFACE_HOST=${HUGGINGFACE_HOST:-huggingface-inference}
      - HUGGINGFACE_PORT=${HUGGINGFACE_PORT:-8082}
      - OLLAMA_HOST=${OLLAMA_HOST:-ollama}
      - OLLAMA_PORT=${OLLAMA_PORT:-11434}
      
      # Development Services
      - GITEA_HOST=${GITEA_HOST:-gitea}
      - GITEA_PORT=${GITEA_PORT:-3002}
      - GITEA_SSH_PORT=${GITEA_SSH_PORT:-222}
      
      # Feature Flags
      - ENABLE_RAG=${ENABLE_RAG:-true}
      - ENABLE_GRAPH_DB=${ENABLE_GRAPH_DB:-true}
      - ENABLE_VECTOR_DB=${ENABLE_VECTOR_DB:-true}
      - ENABLE_MONITORING=${ENABLE_MONITORING:-true}
      - ENABLE_HUGGINGFACE=${ENABLE_HUGGINGFACE:-true}
      - ENABLE_OLLAMA=${ENABLE_OLLAMA:-true}
      - ENABLE_GITEA=${ENABLE_GITEA:-true}
      
    ports:
      - "${API_PORT:-8000}:8000"  # API Server
      - "${WEB_PORT:-3000}:3000"  # Web Dashboard
      - "${CADVISOR_PORT:-8081}:8080"  # Container monitoring
    volumes:
      - ../../src:/app/src
      - ../../config:/app/config
      - ../../public:/app/public
      - ../../logs:/app/logs
      - ../../data:/app/data
    networks:
      - ai-q-network
    depends_on:
      - postgres
      - redis
      - weaviate
      - minio
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: ["./scripts/start-unified.sh"]

  # Infrastructure Services (External dependencies)
  postgres:
    image: postgres:15-alpine
    container_name: ai-q-postgres
    profiles: ["postgres", "core", "full"]
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-aiq_knowledge}
      POSTGRES_USER: ${POSTGRES_USER:-aiq_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-aiq_password}
      POSTGRES_INITDB_ARGS: ${POSTGRES_INITDB_ARGS:---auth-host=scram-sha-256}
    volumes:
      - ai-q-postgres-data:/var/lib/postgresql/data
      - ../../init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-aiq_user} -d ${POSTGRES_DB:-aiq_knowledge}"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    container_name: ai-q-redis
    profiles: ["redis", "core", "full"]
    command: redis-server --appendonly yes
    volumes:
      - ai-q-redis-data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: ai-q-elasticsearch
    profiles: ["elasticsearch", "full"]
    environment:
      - discovery.type=${ELASTICSEARCH_DISCOVERY_TYPE:-single-node}
      - xpack.security.enabled=${ELASTICSEARCH_XPACK_SECURITY_ENABLED:-false}
      - ES_JAVA_OPTS=${ELASTICSEARCH_JAVA_OPTS:--Xms256m -Xmx512m}
      - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD:-elastic}
    volumes:
      - ai-q-elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
      - "${ELASTICSEARCH_CLUSTER_PORT:-9300}:9300"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  neo4j:
    image: neo4j:5.15.0
    container_name: ai-q-neo4j
    profiles: ["neo4j", "full"]
    environment:
      NEO4J_AUTH: ${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-password}
      NEO4J_PLUGINS: ${NEO4J_PLUGINS:-apoc,graph-data-science}
      NEO4J_dbms_security_procedures_unrestricted: ${NEO4J_PROCEDURES_UNRESTRICTED:-gds.*,apoc.*}
      NEO4J_dbms_memory_heap_initial__size: ${NEO4J_HEAP_INITIAL_SIZE:-512m}
      NEO4J_dbms_memory_heap_max__size: ${NEO4J_HEAP_MAX_SIZE:-1G}
      NEO4J_dbms_memory_pagecache_size: ${NEO4J_PAGECACHE_SIZE:-512m}
    volumes:
      - ai-q-neo4j-data:/data
      - ai-q-neo4j-logs:/logs
      - ai-q-neo4j-import:/var/lib/neo4j/import
      - ai-q-neo4j-plugins:/plugins
    ports:
      - "${NEO4J_BROWSER_PORT:-7474}:7474"
      - "${NEO4J_PORT:-7687}:7687"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474/browser/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  weaviate:
    image: semitechnologies/weaviate:1.22.4
    container_name: ai-q-weaviate
    profiles: ["weaviate", "core", "full"]
    environment:
      QUERY_DEFAULTS_LIMIT: ${WEAVIATE_QUERY_DEFAULTS_LIMIT:-25}
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: ${WEAVIATE_AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED:-true}
      PERSISTENCE_DATA_PATH: ${WEAVIATE_PERSISTENCE_DATA_PATH:-/var/lib/weaviate}
      DEFAULT_VECTORIZER_MODULE: ${WEAVIATE_DEFAULT_VECTORIZER_MODULE:-none}
      ENABLE_MODULES: ${WEAVIATE_ENABLE_MODULES:-}
      CLUSTER_HOSTNAME: ${WEAVIATE_CLUSTER_HOSTNAME:-node1}
    volumes:
      - ai-q-weaviate-data:/var/lib/weaviate
    ports:
      - "${WEAVIATE_PORT:-8080}:8080"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  minio:
    image: minio/minio:RELEASE.2023-11-15T20-43-25Z
    container_name: ai-q-minio
    profiles: ["minio", "core", "full"]
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - ai-q-minio-data:/data
    ports:
      - "${MINIO_API_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    networks:
      - ai-q-network
    restart: unless-stopped
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: ai-q-prometheus
    profiles: ["monitoring", "full"]
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ai-q-prometheus-data:/prometheus
      - ../../config/prometheus:/etc/prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  grafana:
    image: grafana/grafana:10.2.0
    container_name: ai-q-grafana
    profiles: ["monitoring", "full"]
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
    volumes:
      - ai-q-grafana-data:/var/lib/grafana
      - ../../config/grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # AI/ML Services
  huggingface-inference:
    image: python:3.11-slim
    container_name: ai-q-huggingface-inference
    profiles: ["ai-ml", "full"]
    environment:
      - TRANSFORMERS_CACHE=${HUGGINGFACE_TRANSFORMERS_CACHE:-/app/cache}
      - HF_HOME=${HUGGINGFACE_HOME:-/app/huggingface}
      - HF_HUB_OFFLINE=${HUGGINGFACE_HUB_OFFLINE:-false}
    volumes:
      - ai-q-huggingface-data:/app/cache
      - ai-q-huggingface-models:/app/models
    ports:
      - "${HUGGINGFACE_PORT:-8082}:8080"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  ollama:
    image: ollama/ollama:latest
    container_name: ai-q-ollama
    profiles: ["ollama", "core", "full"]
    environment:
      - OLLAMA_HOST=${OLLAMA_HOST:-0.0.0.0}
      - OLLAMA_ORIGINS=${OLLAMA_ORIGINS:-*}
      - OLLAMA_MODELS=${OLLAMA_MODELS:-/root/.ollama/models}
    volumes:
      - ai-q-ollama-data:/root/.ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    # Pull default models on startup (smallest/fastest models)
    command: >
      sh -c "
        ollama serve &
        sleep 10 &&
        echo 'Pulling default models (smallest/fastest)...' &&
        for model in ${OLLAMA_DEFAULT_MODELS:-gemma3:2b,llama3.2:3b}; do
          echo 'Pulling model: $model' &&
          ollama pull $model || echo 'Failed to pull $model, continuing...'
        done &&
        wait
      "

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ai-q-openwebui
    profiles: ["ollama", "core", "full"]
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=${OPENWEBUI_SECRET_KEY:-}
      - DEFAULT_MODELS=${OPENWEBUI_DEFAULT_MODELS:-gemma3:2b,llama3.2:3b}
    volumes:
      - ai-q-openwebui-data:/app/backend/data
    ports:
      - "${OPENWEBUI_PORT:-3000}:8080"
    networks:
      - ai-q-network
    depends_on:
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/api/v1/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Development Services
  gitea:
    image: gitea/gitea:1.21.0
    container_name: ai-q-gitea
    profiles: ["development", "full"]
    environment:
      - USER_UID=${GITEA_USER_UID:-1000}
      - USER_GID=${GITEA_USER_GID:-1000}
      - GITEA__database__DB_TYPE=${GITEA_DB_TYPE:-sqlite3}
      - GITEA__database__PATH=${GITEA_DB_PATH:-/data/gitea/gitea.db}
      - GITEA__server__DOMAIN=${GITEA_DOMAIN:-localhost}
      - GITEA__server__ROOT_URL=${GITEA_ROOT_URL:-http://localhost:3002/}
      - GITEA__server__SSH_DOMAIN=${GITEA_SSH_DOMAIN:-localhost}
      - GITEA__server__HTTP_PORT=${GITEA_HTTP_PORT:-3000}
      - GITEA__server__DISABLE_SSH=${GITEA_DISABLE_SSH:-false}
      - GITEA__security__INSTALL_LOCK=${GITEA_INSTALL_LOCK:-true}
      - GITEA__service__DISABLE_REGISTRATION=${GITEA_DISABLE_REGISTRATION:-false}
      - GITEA__service__REQUIRE_SIGNIN_VIEW=${GITEA_REQUIRE_SIGNIN_VIEW:-false}
      - GITEA__log__LEVEL=${GITEA_LOG_LEVEL:-Info}
      - GITEA__log__MODE=${GITEA_LOG_MODE:-console}
    volumes:
      - ai-q-gitea-data:/data
      - ai-q-gitea-config:/data/gitea/conf
    ports:
      - "${GITEA_PORT:-3002}:3000"
      - "${GITEA_SSH_PORT:-222}:22"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/v1/version || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # AI Image Generation Services (GPU Required)
  automatic1111:
    image: automatic1111/stable-diffusion-webui:latest
    container_name: ai-q-automatic1111
    profiles: ["ai-image", "full"]
    environment:
      - COMMANDLINE_ARGS=--listen --port 7860 --enable-insecure-extension-access
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    volumes:
      - ai-q-automatic1111-models:/app/models
      - ai-q-automatic1111-outputs:/app/outputs
      - ai-q-automatic1111-config:/app/config
    ports:
      - "${AUTOMATIC1111_PORT:-7860}:7860"
    networks:
      - ai-q-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:7860/ || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3

  comfyui:
    image: comfyui/comfyui:latest
    container_name: ai-q-comfyui
    profiles: ["ai-image", "full"]
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    volumes:
      - ai-q-comfyui-models:/app/models
      - ai-q-comfyui-outputs:/app/outputs
      - ai-q-comfyui-config:/app/config
    ports:
      - "${COMFYUI_PORT:-8188}:8188"
    networks:
      - ai-q-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8188/ || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Workflow & Automation Services
  n8n:
    image: n8nio/n8n:latest
    container_name: ai-q-n8n
    profiles: ["workflow", "full"]
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=${N8N_PORT:-5678}
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - N8N_USER_MANAGEMENT_DISABLED=${N8N_USER_MANAGEMENT_DISABLED:-false}
      - N8N_BASIC_AUTH_ACTIVE=${N8N_BASIC_AUTH_ACTIVE:-false}
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER:-admin}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD:-admin}
      - N8N_WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://localhost:5678/}
      - N8N_TIMEZONE=${N8N_TIMEZONE:-UTC}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:-}
    volumes:
      - ai-q-n8n-data:/home/node/.n8n
    ports:
      - "${N8N_PORT:-5678}:5678"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5678/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  penpot:
    image: penpot/penpot:latest
    container_name: ai-q-penpot
    profiles: ["design", "full"]
    environment:
      - PENPOT_DATABASE_URI=${PENPOT_DATABASE_URI:-postgresql://penpot:penpot@postgres:5432/penpot}
      - PENPOT_REDIS_URI=${PENPOT_REDIS_URI:-redis://redis:6379/0}
      - PENPOT_SECRET_KEY=${PENPOT_SECRET_KEY:-}
      - PENPOT_PUBLIC_URI=${PENPOT_PUBLIC_URI:-http://localhost:9002}
    volumes:
      - ai-q-penpot-data:/app/data
    ports:
      - "${PENPOT_PORT:-9002}:80"
    networks:
      - ai-q-network
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Self-Hosted Services
  nextcloud:
    image: nextcloud:25.0.0
    container_name: ai-q-nextcloud
    profiles: ["storage", "full"]
    environment:
      - NEXTCLOUD_ADMIN_USER=${NEXTCLOUD_ADMIN_USER:-admin}
      - NEXTCLOUD_ADMIN_PASSWORD=${NEXTCLOUD_ADMIN_PASSWORD:-admin123}
      - NEXTCLOUD_DB_PASSWORD=${NEXTCLOUD_DB_PASSWORD:-nextcloud123}
    volumes:
      - ai-q-nextcloud-data:/var/www/html
      - ai-q-nextcloud-config:/var/www/html/config
    ports:
      - "${NEXTCLOUD_PORT:-8083}:80"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/status.php || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  admin-panel:
    image: portainer/portainer-ce:latest
    container_name: ai-q-admin-panel
    profiles: ["infrastructure", "full"]
    environment:
      - ADMIN_PANEL_PORT=${ADMIN_PANEL_PORT:-9003}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ai-q-admin-panel-data:/data
    ports:
      - "${ADMIN_PANEL_PORT:-9003}:9000"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  registry:
    image: registry:2.8.2
    container_name: ai-q-registry
    profiles: ["infrastructure", "full"]
    environment:
      - REGISTRY_PORT=${REGISTRY_PORT:-5000}
    volumes:
      - ai-q-registry-data:/var/lib/registry
    ports:
      - "${REGISTRY_PORT:-5000}:5000"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5000/v2/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Load Balancer & Proxy
  nginx:
    image: nginx:alpine
    container_name: ai-q-nginx
    profiles: ["infrastructure", "full"]
    environment:
      - NGINX_PORT=${NGINX_PORT:-80}
      - NGINX_SSL_PORT=${NGINX_SSL_PORT:-443}
    volumes:
      - ai-q-nginx-config:/etc/nginx/conf.d
      - ai-q-nginx-logs:/var/log/nginx
      - ${SSL_CERT_PATH:-/dev/null}:/etc/nginx/ssl/cert.pem:ro
      - ${SSL_KEY_PATH:-/dev/null}:/etc/nginx/ssl/key.pem:ro
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring Services
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: ai-q-cadvisor
    profiles: ["monitoring", "full"]
    privileged: true
    devices:
      - /dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    ports:
      - "${CADVISOR_PORT:-8081}:8080"
    networks:
      - ai-q-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  ai-q-postgres-data:
  ai-q-redis-data:
  ai-q-elasticsearch-data:
  ai-q-neo4j-data:
  ai-q-neo4j-logs:
  ai-q-neo4j-import:
  ai-q-neo4j-plugins:
  ai-q-weaviate-data:
  ai-q-minio-data:
  ai-q-grafana-data:
  ai-q-prometheus-data:
  ai-q-huggingface-data:
  ai-q-huggingface-models:
  ai-q-ollama-data:
  ai-q-openwebui-data:
  ai-q-gitea-data:
  ai-q-gitea-config:
  ai-q-automatic1111-models:
  ai-q-automatic1111-outputs:
  ai-q-automatic1111-config:
  ai-q-comfyui-models:
  ai-q-comfyui-outputs:
  ai-q-comfyui-config:
  ai-q-n8n-data:
  ai-q-penpot-data:
  ai-q-nextcloud-data:
  ai-q-nextcloud-config:
  ai-q-admin-panel-data:
  ai-q-registry-data:
  ai-q-nginx-config:
  ai-q-nginx-logs:

networks:
  ai-q-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16 